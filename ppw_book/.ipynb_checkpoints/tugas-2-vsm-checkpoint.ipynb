{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba212ae-961a-484f-b38e-bf97969ef5c5",
   "metadata": {},
   "source": [
    "# Modelling Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b432d2-558c-4185-9571-31fc5487f63a",
   "metadata": {},
   "source": [
    "## Apa itu Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e945d-3412-4f30-a7a8-417a8675d8e8",
   "metadata": {},
   "source": [
    "Vector Space Model (VSM) adalah model matematika yang digunakan untuk merepresentasikan dokumen teks sebagai vektor dari identifikator (seperti kata-kata atau token). Model ini adalah bagian fundamental dalam sistem informasi pencarian dan teknik pemrosesan bahasa alami untuk menilai dan mengurutkan dokumen berdasarkan relevansinya terhadap suatu query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f80304-d61f-46ea-a1ba-9f8e5b442191",
   "metadata": {},
   "source": [
    "### Konsep Dasar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4673cd2-0e3f-489e-8f5a-6b827b9feedb",
   "metadata": {},
   "source": [
    "Dalam VSM, setiap dimensi vektor mewakili sebuah term (kata) yang unik dalam dokumen. Nilai dalam vektor ini bisa merupakan frekuensi kemunculan kata, atau bobot yang lebih kompleks seperti TF-IDF, yang menggabungkan frekuensi kata dalam dokumen (TF) dan kebalikan frekuensi dokumen (IDF). Setiap dokumen direpresentasikan sebagai titik dalam ruang vektor ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4cfdc-c0b6-4466-94b2-a87c0204b50e",
   "metadata": {},
   "source": [
    "### Kegunaan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f92ec-6bb7-4089-807f-3847c79fe69d",
   "metadata": {},
   "source": [
    "Model ini sangat berguna dalam sistem pencarian dan pengambilan informasi karena memungkinkan operasi seperti pencarian kecocokan dan perankingan dilakukan secara matematis. VSM memfasilitasi pencocokan query pencarian dengan koleksi dokumen melalui perhitungan kedekatan vektor, menggunakan teknik seperti cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96786b4-697a-4a85-9284-af3ca696893e",
   "metadata": {},
   "source": [
    "### Keunggulan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb653836-7280-4c87-93b7-ca7f7a2528e6",
   "metadata": {},
   "source": [
    "- **Flexibilitas**: VSM memungkinkan penyertaan berbagai metode penghitungan bobot selain frekuensi term, seperti TF-IDF, yang meningkatkan efektivitas model dalam menghadapi isu seperti kata-kata yang sangat umum yang muncul di banyak dokumen.\n",
    "- **Efisiensi**: Meskipun representasi vektor dapat menjadi sangat besar, teknik seperti sparse matrix operations memungkinkan pemrosesan yang efisien.\n",
    "- **Kemampuan Komparatif**: Dengan merepresentasikan dokumen sebagai vektor, mudah untuk mengukur kesamaan antar dokumen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052984f-c71f-4a09-9e30-13c45032b475",
   "metadata": {},
   "source": [
    "### Keterbatasan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a759d5f-a50d-4781-bb6e-33cf3e6b0813",
   "metadata": {},
   "source": [
    "- **Semantik**: VSM tidak memperhitungkan konteks dan makna semantik dari kata-kata, yang bisa mengakibatkan dokumen yang sebenarnya berkaitan tidak dikenali sebagai relevan.\n",
    "- **Sinonim dan Polisemi**: Kata-kata dengan makna ganda atau sinonim mungkin tidak diproses dengan efektif, karena model ini berfokus pada kata-kata sebagai entitas independen tanpa mempertimbangkan hubungan semantiknya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea633e-438b-4411-9fd3-8df2c0a8021c",
   "metadata": {},
   "source": [
    "## Konsep TF-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad26a08e-6ff0-469c-bbec-759abd0ccd37",
   "metadata": {},
   "source": [
    "Metode  Term  Frequency-Inverse Document Frequency (TF-IDF) adalah salah satu  teknik  representasi  teks yang mengonversi kata-kata menjadi  nilai  numerik  berdasarkan  seberapa  sering kata tersebut  muncul  dalam  teks  serta  seberapa  umumnya kata tersebut  dalam  kumpulan  dokumen yang tersedia. Bobot  numerik yang dihasilkan oleh metode  ini  sering  disebut  sebagai  bobot TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71beef28-5cfe-4b01-9966-4c94165d3c9b",
   "metadata": {},
   "source": [
    "### Term Frequency (TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7b398-77ba-4207-9a21-18f601756fe1",
   "metadata": {},
   "source": [
    "**Term Frequency**: Dalam  dokumen d, frekuensi  merepresentasikan  jumlah  kemunculan kata t. Oleh karena  itu, kita  dapat  melihat  bahwa  frekuensi  menjadi  lebih  relevan  ketika  sebuah kata muncul di dalam  teks, yang mana hal  ini  rasional. Karena urutan  istilah  tidak  signifikan, kita  dapat  menggunakan  vektor  untuk  menggambarkan  teks  dalam  kantong model istilah. Untuk  setiap  istilah  tertentu  dalam  teks, ada  sebuah  entri  dengan  nilai yang merupakan  frekuensi  istilah. Bobot  sebuah  istilah yang muncul  dalam  sebuah  dokumen  secara  sederhana  sebanding  dengan  frekuensi  istilah  tersebut\n",
    "\n",
    "\n",
    "$$\n",
    "    tf(t, d) = \\frac{\\text{jumalah } t \\text{ dalam } d}{\\text{jumlah kata dalam } d}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**Dokument Frequency**: mengukur  seberapa  umumnya  suatu kata terjadi di seluruh  koleksi  dokumen. Konsep  ini  mirip  dengan Term Frequency (TF), namun  perbedaannya  terletak pada bagaimana  kita  menghitung  kemunculan  suatu kata. Di TF, kita  melihat  seberapa  sering kata muncul  dalam  satu  dokumen  tertentu, sedangkan di DF, kita  melihat  berapa  banyak  dokumen yang mengandung kata tersebut di dalam  keseluruhan  koleksi  dokumen. Jadi, Document Frequency (DF) adalah  jumlah  dokumen yang memuat  suatu kata.\n",
    "\n",
    "$$\n",
    "    df(t) = \\text{kemunculan } t \\text{ dalam } dokumen \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b485854-a92c-471d-80d2-1f2da7440d19",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a871eb4d-7059-4922-b2ca-863cd7acdcad",
   "metadata": {},
   "source": [
    "**Inverse Document Frequency (IDF)**: mengevaluasi tingkat relevansi suatu kata dalam konteks pencarian. Ketika mencari informasi, tujuan utama adalah menemukan dokumen yang paling sesuai dengan permintaan pengguna. Mengingat bahwa Term Frequency (TF) memperlakukan semua kata dengan nilai yang sama, frekuensi kata itu sendiri tidak cukup untuk menilai  bobot istilah dalam sebuah dokumen. IDF pertama-tama mencari frekuensi kemunculan dokumen untuk suatu kata dengan menghitung jumlah dokumen yang mengandung kata tersebut.\n",
    "\n",
    "$$\n",
    "    df(t) = N(t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    df(t) = \\text{Frekuensi dokumen dari suatu istilah t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    N(t) = \\text{Jumlah } dokumen \\text{ yang mengandung istilah } t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e1c7c-ac5e-402e-8f6e-727c0f0d950f",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dea39c-7929-49c9-84f2-149f1080638b",
   "metadata": {},
   "source": [
    "Term Frequency adalah jumlah kemunculan suatu istilah dalam satu dokumen saja, sedangkan Document Frequency adalah jumlah dokumen terpisah tempat istilah tersebut muncul. Namun, frekuensi ini bergantung pada seluruh korpus. IDF merupakan jumlah dokumen dalam korpus yang dipisahkan oleh frekuensi teks. Dengan kata lain, IDF mengukur seberapa umum atau langka suatu kata dalam seluruh koleksi dokumen.\n",
    "\n",
    "$$\n",
    "    idf(t) = \\frac{N}{df(t)}=\\frac{N}{N(t)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    idf(t) = log_2 \\frac{N}{df(t)}\n",
    "$$\n",
    "\n",
    "Maka dari itu rumus dari TF * IDF adalah sebagai berikut:\n",
    "\n",
    "$$\n",
    "    tf-idf(t, d) = tf(t, d) * idf(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f19a1-d93e-4ccb-82e4-9c553895c73a",
   "metadata": {},
   "source": [
    "## Modelling SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea207d6-dd39-4b9f-bfd6-aa759ddf3a0d",
   "metadata": {},
   "source": [
    "### Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11ea8d69-4555-412b-9954-08012a648457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library yang dibutuhkan \n",
    "import pandas as pd\n",
    "import re\n",
    "import tqdm\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4007f0d-6bba-4436-8d9a-cb822d8ee012",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data-artikel-cnbc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c44ab6-6096-47f4-870a-515166173954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>isi</th>\n",
       "      <th>url</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>09 September 2024 19:30</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Kedatangan pemain-pem...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>09 September 2024 19:05</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Sepanjang paruh perta...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>09 September 2024 18:10</td>\n",
       "      <td>Jakarta,CNBC Indonesia -Harga emas dunia melem...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>09 September 2024 15:55</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Indeks Harga Konsumen...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>09 September 2024 14:35</td>\n",
       "      <td>Jakarta, CNBC Indonesia-Tentara Nasional Indon...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul                  tanggal  \\\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...  09 September 2024 19:30   \n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...  09 September 2024 19:05   \n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...  09 September 2024 18:10   \n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...  09 September 2024 15:55   \n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...  09 September 2024 14:35   \n",
       "\n",
       "                                                 isi  \\\n",
       "0  Jakarta, CNBC Indonesia -Kedatangan pemain-pem...   \n",
       "1  Jakarta, CNBC Indonesia -Sepanjang paruh perta...   \n",
       "2  Jakarta,CNBC Indonesia -Harga emas dunia melem...   \n",
       "3  Jakarta, CNBC Indonesia -Indeks Harga Konsumen...   \n",
       "4  Jakarta, CNBC Indonesia-Tentara Nasional Indon...   \n",
       "\n",
       "                                                 url  kategori  \n",
       "0  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "1  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "2  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "3  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "4  https://www.cnbcindonesia.com/research/2024090...  Research  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bcd779f-a60a-4957-b864-32be6ce2d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  kategori\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...  Research\n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...  Research\n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...  Research\n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...  Research\n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...  Research"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hanya memilih kolom judul dan kategori\n",
    "df = df[['judul', 'kategori']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "638fa620-4b0f-4b4f-9b82-7837c8e5a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data untuk kategori \"Research\"\n",
    "research = df[df[\"kategori\"] == \"Research\"].sample(n=50, random_state=42)\n",
    "news = df[df[\"kategori\"] == \"News\"].sample(n=50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb4e7672-ce4c-481c-97ee-2fd121c2bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan keduanya tanpa mempertahankan indeks\n",
    "data = pd.concat([research, news], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6030e6d5-325d-4da3-9321-014164040ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   judul     100 non-null    object\n",
      " 1   kategori  100 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4daec17-354b-4e7d-b170-9533d62b7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d52f9949-0510-4544-9730-ce40888a6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(text):\n",
    "    text = re.sub(r'[^\\w\\s-]', ' ', text) # Menghapus karakter yang bukan huruf, angka, spasi, atau tanda minus\n",
    "    text = text.encode('ascii', 'ignore').decode('utf-8') # Menghapus karakter non-ASCII dengan mengabaikan karakter yang tidak bisa di-encode ke ASCII\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', r'', text) # Menghapus semua karakter non-ASCII (karakter di luar rentang 0-127 dalam kode ASCII)\n",
    "    text = text.lower() # Mengubah teks menjadi huruf kecil\n",
    "    text = text.split() # Memecah teks menjadi daftar kata-kata\n",
    "    text = [word for word in text if word not in stopwords] # Setelah dipecah dicek apakah masuk stopword atau tidak\n",
    "    text = ' '.join(text) # Menggabungkan kembali daftar kata-kata menjadi satu string yang dipisahkan oleh spasi\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e662e0-e3d6-4d50-bac9-b68ad0e548ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sastrawistemmer(text):\n",
    "    factory = StemmerFactory()\n",
    "    st = factory.create_stemmer()\n",
    "    text = ' '.join(st.stem(word) for word in tqdm(text.split()) if word in text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "651978f8-4ac1-4eb1-a7d8-ec0181f9b227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  kategori\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...  Research\n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...  Research\n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...  Research\n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...  Research\n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...  Research"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce10fb26-8f0d-469b-80ec-4f9e9fc967cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(text):\n",
    "    # text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    text = text.encode('ascii','ignore').decode('utf-8')\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [word for word in text if word not in stopwords.words('indonesian')]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd8c13e9-f74b-4290-a4ff-ddee900edad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleansing\"] = df[\"judul\"].apply(clean_and_process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d0acdc8-2ba6-41d1-8cfc-c646d6d6fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_process_text(text):\n",
    "    # Langkah pembersihan teks\n",
    "    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', text)  # Menghapus https* dan www*\n",
    "    text = re.sub(r'@[^\\s]+', ' ', text)  # Menghapus username\n",
    "    text = re.sub(r'[\\s]+', ' ', text)  # Menghapus tambahan spasi\n",
    "    text = re.sub(r'#([^\\s]+)', ' ', text)  # Menghapus hashtags\n",
    "    text = re.sub(r'rt', ' ', text)  # Menghapus retweet\n",
    "    text = re.sub(r'[^\\w\\s]+', ' ', text)  # Menghapus tanda baca\n",
    "    text = re.sub(r'\\d', ' ', text)  # Menghapus angka\n",
    "    text = text.lower()  # Mengubah teks menjadi huruf kecil\n",
    "    text = text.encode('ascii', 'ignore').decode('utf-8')  # Menghapus karakter non-ASCII\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', r'', text)  # Menghapus karakter non-ASCII yang tersisa\n",
    "    text = text.replace('\\n', '')  # Menghapus baris baru\n",
    "\n",
    "    # Langkah stemming\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "    stemmed_text = stemmer.stem(text)\n",
    "\n",
    "    # Tokenisasi\n",
    "    tokens = nltk.tokenize.word_tokenize(stemmed_text)\n",
    "\n",
    "    # Menghapus stopwords menggunakan bahasa Indonesia\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    filtered_words = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Gabungkan kembali kata-kata yang sudah difilter menjadi teks\n",
    "    processed_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a501054b-2fff-4a4e-ad62-49f57823d9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>kategori</th>\n",
       "      <th>cleansing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>Research</td>\n",
       "      <td>kaleng kaleng nilai skuad timnas indonesia mew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>Research</td>\n",
       "      <td>aset bank mandiri tembus rp t jumbo indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>Research</td>\n",
       "      <td>emas redup suku bunga the fed turun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>Research</td>\n",
       "      <td>tetangga ri hantam bencana iklim harga barang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>Research</td>\n",
       "      <td>tantama perwira urut lengkap pangkat tni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  kategori  \\\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...  Research   \n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...  Research   \n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...  Research   \n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...  Research   \n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...  Research   \n",
       "\n",
       "                                           cleansing  \n",
       "0  kaleng kaleng nilai skuad timnas indonesia mew...  \n",
       "1      aset bank mandiri tembus rp t jumbo indonesia  \n",
       "2                emas redup suku bunga the fed turun  \n",
       "3  tetangga ri hantam bencana iklim harga barang ...  \n",
       "4           tantama perwira urut lengkap pangkat tni  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c2435-dbb8-4788-9c3d-6885a2e451f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d253b8a9-4d27-4d65-9fd6-3321dc7aef6a",
   "metadata": {},
   "source": [
    "#### Tokenisasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e080a4-8cbc-4818-baf4-e9c5d1770b7e",
   "metadata": {},
   "source": [
    "#### Normalisasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949728b0-c1f7-43a5-9134-30e17fd969db",
   "metadata": {},
   "source": [
    "#### Stopword Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d53a6d-fab8-4814-9fb9-521db79820e5",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ba9d8-e8bb-4795-9b41-00f1c63a89fc",
   "metadata": {},
   "source": [
    "### Perhitungan TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30d17f46-15b5-461e-9bbd-c3c76b5a7bcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m vsm_df \u001b[38;5;241m=\u001b[39m create_vsm(docs)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Tampilkan hasil\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mace_tools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m \n\u001b[0;32m     31\u001b[0m tools\u001b[38;5;241m.\u001b[39mdisplay_dataframe_to_user(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVector Space Model DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataframe\u001b[38;5;241m=\u001b[39mvsm_df)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fungsi untuk membuat Vector Space Model menggunakan TF-IDF\n",
    "def create_vsm(docs):\n",
    "    # Inisialisasi TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Transformasi dokumen menjadi vektor TF-IDF\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "\n",
    "    # Mendapatkan fitur (kata-kata yang diambil oleh vectorizer)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Mengubah hasil TF-IDF menjadi DataFrame\n",
    "    df_vsm = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "    return df_vsm\n",
    "\n",
    "# Asumsikan df[\"cleansing\"] sudah berisi teks yang sudah dibersihkan dan diproses\n",
    "# Contoh: df[\"cleansing\"] = df[\"text\"].apply(clean_and_process_text)\n",
    "\n",
    "# Ambil teks dari kolom df[\"cleansing\"] untuk digunakan dalam VSM\n",
    "docs = df[\"cleansing\"].tolist()\n",
    "\n",
    "# Buat Vector Space Model dan simpan ke dalam DataFrame\n",
    "vsm_df = create_vsm(docs)\n",
    "\n",
    "# Tampilkan hasil\n",
    "import ace_tools as tools \n",
    "tools.display_dataframe_to_user(name=\"Vector Space Model DataFrame\", dataframe=vsm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "824d76fd-d5b8-49ec-8c1f-751961a35695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aali</th>\n",
       "      <th>abad</th>\n",
       "      <th>acak</th>\n",
       "      <th>ace</th>\n",
       "      <th>aceh</th>\n",
       "      <th>acme</th>\n",
       "      <th>adat</th>\n",
       "      <th>ades</th>\n",
       "      <th>adhi</th>\n",
       "      <th>adopsi</th>\n",
       "      <th>...</th>\n",
       "      <th>whoosh</th>\n",
       "      <th>wib</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>wisesa</th>\n",
       "      <th>wskt</th>\n",
       "      <th>xxi</th>\n",
       "      <th>yellen</th>\n",
       "      <th>yordania</th>\n",
       "      <th>yoy</th>\n",
       "      <th>zulhas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 1196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aali  abad  acak  ace  aceh  acme  adat  ades  adhi  adopsi  ...  whoosh  \\\n",
       "0     0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "1     0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "2     0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "3     0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "4     0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "..    ...   ...   ...  ...   ...   ...   ...   ...   ...     ...  ...     ...   \n",
       "393   0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "394   0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "395   0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "396   0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "397   0.0   0.0   0.0  0.0   0.0   0.0   0.0   0.0   0.0     0.0  ...     0.0   \n",
       "\n",
       "     wib  wilayah  wisesa  wskt  xxi  yellen  yordania  yoy  zulhas  \n",
       "0    0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "1    0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "2    0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "3    0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "4    0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "..   ...      ...     ...   ...  ...     ...       ...  ...     ...  \n",
       "393  0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "394  0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "395  0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "396  0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "397  0.0      0.0     0.0   0.0  0.0     0.0       0.0  0.0     0.0  \n",
       "\n",
       "[398 rows x 1196 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bcdd7-a3d2-4605-821f-e84a64fec4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96534b9-de0c-40b6-bc9a-92b39bada369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a30c1-e769-4630-bc8c-edf97b18673d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
