{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba212ae-961a-484f-b38e-bf97969ef5c5",
   "metadata": {},
   "source": [
    "# Modelling Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b432d2-558c-4185-9571-31fc5487f63a",
   "metadata": {},
   "source": [
    "## Apa itu Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e945d-3412-4f30-a7a8-417a8675d8e8",
   "metadata": {},
   "source": [
    "Vector Space Model (VSM) adalah model matematika yang digunakan untuk merepresentasikan dokumen teks sebagai vektor dari identifikator (seperti kata-kata atau token). Model ini adalah bagian fundamental dalam sistem informasi pencarian dan teknik pemrosesan bahasa alami untuk menilai dan mengurutkan dokumen berdasarkan relevansinya terhadap suatu query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f80304-d61f-46ea-a1ba-9f8e5b442191",
   "metadata": {},
   "source": [
    "### Konsep Dasar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4673cd2-0e3f-489e-8f5a-6b827b9feedb",
   "metadata": {},
   "source": [
    "Dalam VSM, setiap dimensi vektor mewakili sebuah term (kata) yang unik dalam dokumen. Nilai dalam vektor ini bisa merupakan frekuensi kemunculan kata, atau bobot yang lebih kompleks seperti TF-IDF, yang menggabungkan frekuensi kata dalam dokumen (TF) dan kebalikan frekuensi dokumen (IDF). Setiap dokumen direpresentasikan sebagai titik dalam ruang vektor ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4cfdc-c0b6-4466-94b2-a87c0204b50e",
   "metadata": {},
   "source": [
    "### Kegunaan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f92ec-6bb7-4089-807f-3847c79fe69d",
   "metadata": {},
   "source": [
    "Model ini sangat berguna dalam sistem pencarian dan pengambilan informasi karena memungkinkan operasi seperti pencarian kecocokan dan perankingan dilakukan secara matematis. VSM memfasilitasi pencocokan query pencarian dengan koleksi dokumen melalui perhitungan kedekatan vektor, menggunakan teknik seperti cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96786b4-697a-4a85-9284-af3ca696893e",
   "metadata": {},
   "source": [
    "### Keunggulan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb653836-7280-4c87-93b7-ca7f7a2528e6",
   "metadata": {},
   "source": [
    "- **Flexibilitas**: VSM memungkinkan penyertaan berbagai metode penghitungan bobot selain frekuensi term, seperti TF-IDF, yang meningkatkan efektivitas model dalam menghadapi isu seperti kata-kata yang sangat umum yang muncul di banyak dokumen.\n",
    "- **Efisiensi**: Meskipun representasi vektor dapat menjadi sangat besar, teknik seperti sparse matrix operations memungkinkan pemrosesan yang efisien.\n",
    "- **Kemampuan Komparatif**: Dengan merepresentasikan dokumen sebagai vektor, mudah untuk mengukur kesamaan antar dokumen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052984f-c71f-4a09-9e30-13c45032b475",
   "metadata": {},
   "source": [
    "### Keterbatasan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a759d5f-a50d-4781-bb6e-33cf3e6b0813",
   "metadata": {},
   "source": [
    "- **Semantik**: VSM tidak memperhitungkan konteks dan makna semantik dari kata-kata, yang bisa mengakibatkan dokumen yang sebenarnya berkaitan tidak dikenali sebagai relevan.\n",
    "- **Sinonim dan Polisemi**: Kata-kata dengan makna ganda atau sinonim mungkin tidak diproses dengan efektif, karena model ini berfokus pada kata-kata sebagai entitas independen tanpa mempertimbangkan hubungan semantiknya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea633e-438b-4411-9fd3-8df2c0a8021c",
   "metadata": {},
   "source": [
    "## Konsep TF-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad26a08e-6ff0-469c-bbec-759abd0ccd37",
   "metadata": {},
   "source": [
    "Metode  Term  Frequency-Inverse Document Frequency (TF-IDF) adalah salah satu  teknik  representasi  teks yang mengonversi kata-kata menjadi  nilai  numerik  berdasarkan  seberapa  sering kata tersebut  muncul  dalam  teks  serta  seberapa  umumnya kata tersebut  dalam  kumpulan  dokumen yang tersedia. Bobot  numerik yang dihasilkan oleh metode  ini  sering  disebut  sebagai  bobot TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71beef28-5cfe-4b01-9966-4c94165d3c9b",
   "metadata": {},
   "source": [
    "### Term Frequency (TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7b398-77ba-4207-9a21-18f601756fe1",
   "metadata": {},
   "source": [
    "**Term Frequency**: Dalam  dokumen d, frekuensi  merepresentasikan  jumlah  kemunculan kata t. Oleh karena  itu, kita  dapat  melihat  bahwa  frekuensi  menjadi  lebih  relevan  ketika  sebuah kata muncul di dalam  teks, yang mana hal  ini  rasional. Karena urutan  istilah  tidak  signifikan, kita  dapat  menggunakan  vektor  untuk  menggambarkan  teks  dalam  kantong model istilah. Untuk  setiap  istilah  tertentu  dalam  teks, ada  sebuah  entri  dengan  nilai yang merupakan  frekuensi  istilah. Bobot  sebuah  istilah yang muncul  dalam  sebuah  dokumen  secara  sederhana  sebanding  dengan  frekuensi  istilah  tersebut\n",
    "\n",
    "\n",
    "$$\n",
    "    tf(t, d) = \\frac{\\text{jumalah } t \\text{ dalam } d}{\\text{jumlah kata dalam } d}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**Dokument Frequency**: mengukur  seberapa  umumnya  suatu kata terjadi di seluruh  koleksi  dokumen. Konsep  ini  mirip  dengan Term Frequency (TF), namun  perbedaannya  terletak pada bagaimana  kita  menghitung  kemunculan  suatu kata. Di TF, kita  melihat  seberapa  sering kata muncul  dalam  satu  dokumen  tertentu, sedangkan di DF, kita  melihat  berapa  banyak  dokumen yang mengandung kata tersebut di dalam  keseluruhan  koleksi  dokumen. Jadi, Document Frequency (DF) adalah  jumlah  dokumen yang memuat  suatu kata.\n",
    "\n",
    "$$\n",
    "    df(t) = \\text{kemunculan } t \\text{ dalam } dokumen \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b485854-a92c-471d-80d2-1f2da7440d19",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a871eb4d-7059-4922-b2ca-863cd7acdcad",
   "metadata": {},
   "source": [
    "**Inverse Document Frequency (IDF)**: mengevaluasi tingkat relevansi suatu kata dalam konteks pencarian. Ketika mencari informasi, tujuan utama adalah menemukan dokumen yang paling sesuai dengan permintaan pengguna. Mengingat bahwa Term Frequency (TF) memperlakukan semua kata dengan nilai yang sama, frekuensi kata itu sendiri tidak cukup untuk menilai  bobot istilah dalam sebuah dokumen. IDF pertama-tama mencari frekuensi kemunculan dokumen untuk suatu kata dengan menghitung jumlah dokumen yang mengandung kata tersebut.\n",
    "\n",
    "$$\n",
    "    df(t) = N(t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    df(t) = \\text{Frekuensi dokumen dari suatu istilah t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    N(t) = \\text{Jumlah } dokumen \\text{ yang mengandung istilah } t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e1c7c-ac5e-402e-8f6e-727c0f0d950f",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dea39c-7929-49c9-84f2-149f1080638b",
   "metadata": {},
   "source": [
    "Term Frequency adalah jumlah kemunculan suatu term dalam satu dokumen saja, sedangkan Document Frequency adalah jumlah dokumen terpisah tempat istilah tersebut muncul. Namun, frekuensi ini bergantung pada seluruh korpus. IDF merupakan jumlah dokumen dalam korpus yang dipisahkan oleh frekuensi teks. Dengan kata lain, IDF mengukur seberapa umum atau langka suatu kata dalam seluruh koleksi dokumen.\n",
    "\n",
    "$$\n",
    "    idf(t) = \\frac{N}{df(t)}=\\frac{N}{N(t)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    idf(t) = log_2 \\frac{N}{df(t)}\n",
    "$$\n",
    "\n",
    "Maka dari itu rumus dari TF * IDF adalah sebagai berikut:\n",
    "\n",
    "$$\n",
    "    tf-idf(t, d) = tf(t, d) * idf(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f19a1-d93e-4ccb-82e4-9c553895c73a",
   "metadata": {},
   "source": [
    "## Modelling SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea207d6-dd39-4b9f-bfd6-aa759ddf3a0d",
   "metadata": {},
   "source": [
    "### Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ea8d69-4555-412b-9954-08012a648457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library yang dibutuhkan \n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a45f2-23c5-4ea0-8300-3ea2acf75c65",
   "metadata": {},
   "source": [
    "Data yang sebelumnya sudah discrapping pada [tugas 1](https://rrayhka.github.io/pencarian-penambangan-web/tugas-1-crawling.html#convert-data-ke-dalam-csv) diimport untuk dijadikan VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4007f0d-6bba-4436-8d9a-cb822d8ee012",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data-artikel-cnbc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c44ab6-6096-47f4-870a-515166173954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>isi</th>\n",
       "      <th>url</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>09 September 2024 19:30</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Kedatangan pemain-pem...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>09 September 2024 19:05</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Sepanjang paruh perta...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>09 September 2024 18:10</td>\n",
       "      <td>Jakarta,CNBC Indonesia -Harga emas dunia melem...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>09 September 2024 15:55</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Indeks Harga Konsumen...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>09 September 2024 14:35</td>\n",
       "      <td>Jakarta, CNBC Indonesia-Tentara Nasional Indon...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul                  tanggal  \\\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...  09 September 2024 19:30   \n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...  09 September 2024 19:05   \n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...  09 September 2024 18:10   \n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...  09 September 2024 15:55   \n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...  09 September 2024 14:35   \n",
       "\n",
       "                                                 isi  \\\n",
       "0  Jakarta, CNBC Indonesia -Kedatangan pemain-pem...   \n",
       "1  Jakarta, CNBC Indonesia -Sepanjang paruh perta...   \n",
       "2  Jakarta,CNBC Indonesia -Harga emas dunia melem...   \n",
       "3  Jakarta, CNBC Indonesia -Indeks Harga Konsumen...   \n",
       "4  Jakarta, CNBC Indonesia-Tentara Nasional Indon...   \n",
       "\n",
       "                                                 url  kategori  \n",
       "0  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "1  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "2  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "3  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "4  https://www.cnbcindonesia.com/research/2024090...  Research  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bcd779f-a60a-4957-b864-32be6ce2d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>isi</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Kedatangan pemain-pem...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Sepanjang paruh perta...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>Jakarta,CNBC Indonesia -Harga emas dunia melem...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Indeks Harga Konsumen...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>Jakarta, CNBC Indonesia-Tentara Nasional Indon...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...   \n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...   \n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...   \n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...   \n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...   \n",
       "\n",
       "                                                 isi  kategori  \n",
       "0  Jakarta, CNBC Indonesia -Kedatangan pemain-pem...  Research  \n",
       "1  Jakarta, CNBC Indonesia -Sepanjang paruh perta...  Research  \n",
       "2  Jakarta,CNBC Indonesia -Harga emas dunia melem...  Research  \n",
       "3  Jakarta, CNBC Indonesia -Indeks Harga Konsumen...  Research  \n",
       "4  Jakarta, CNBC Indonesia-Tentara Nasional Indon...  Research  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hanya memilih kolom judul, isi, dan kategori\n",
    "df = df[['judul', 'isi','kategori']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638fa620-4b0f-4b4f-9b82-7837c8e5a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data untuk kategori \"Research\" dan \"News\" masing-masing diambil 50 berita\n",
    "research = df[df[\"kategori\"] == \"Research\"].sample(n=50, random_state=42)\n",
    "news = df[df[\"kategori\"] == \"News\"].sample(n=50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4e7672-ce4c-481c-97ee-2fd121c2bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan keduanya\n",
    "data = pd.concat([research, news], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6030e6d5-325d-4da3-9321-014164040ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   judul     100 non-null    object\n",
      " 1   isi       100 non-null    object\n",
      " 2   kategori  100 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651978f8-4ac1-4eb1-a7d8-ec0181f9b227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>isi</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Kedatangan pemain-pem...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Sepanjang paruh perta...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>Jakarta,CNBC Indonesia -Harga emas dunia melem...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Indeks Harga Konsumen...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>Jakarta, CNBC Indonesia-Tentara Nasional Indon...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...   \n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...   \n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...   \n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...   \n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...   \n",
       "\n",
       "                                                 isi  kategori  \n",
       "0  Jakarta, CNBC Indonesia -Kedatangan pemain-pem...  Research  \n",
       "1  Jakarta, CNBC Indonesia -Sepanjang paruh perta...  Research  \n",
       "2  Jakarta,CNBC Indonesia -Harga emas dunia melem...  Research  \n",
       "3  Jakarta, CNBC Indonesia -Indeks Harga Konsumen...  Research  \n",
       "4  Jakarta, CNBC Indonesia-Tentara Nasional Indon...  Research  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb011254-f714-4783-9d4c-dba5ccc42948",
   "metadata": {},
   "source": [
    "#### Cleansing Function\n",
    "\n",
    "1. **Pembersihan Teks**:\n",
    "       - Menghapus URL yang diawali dengan \"www.\" atau \"https://\", agar tidak mengganggu hasil analisis.\n",
    "       - Menghapus mention username yang diawali dengan '@' untuk menghindari gangguan dari referensi ke akun sosial media.\n",
    "       - Menghapus spasi berlebih yang muncul akibat pembersihan teks sebelumnya.\n",
    "       - Menghapus hashtag (kata yang diawali dengan '#'), karena hashtag tidak diperlukan dalam analisis konten.\n",
    "       - Menghapus teks 'RT' (retweet) yang biasa ditemukan dalam tweet.\n",
    "       - Menghapus tanda baca seperti titik, koma, tanda seru, dan karakter non-alfanumerik lainnya.\n",
    "       - Menghapus angka dari teks karena angka biasanya tidak berkontribusi pada pemahaman konteks dalam teks (kecuali dalam analisis numerik).\n",
    "       - Mengubah teks menjadi huruf kecil agar seragam dalam pengolahan, terutama dalam analisis berbasis kata.\n",
    "       - Menghapus karakter non-ASCII untuk menghindari simbol atau karakter yang tidak dikenal di encoding ASCII.\n",
    "       - Menghapus karakter tambahan non-ASCII yang mungkin masih tersisa di dalam teks.\n",
    "       - Menghapus baris baru ('\\n') agar hasilnya berupa satu baris teks yang konsisten.\n",
    "\n",
    "2. **Stemming**:\n",
    "       - Menggunakan library `Sastrawi` untuk stemming teks bahasa Indonesia. Stemming adalah proses mengubah kata-kata menjadi bentuk dasar (akar kata), \n",
    "         sehingga kata yang beragam seperti \"makan\", \"memakan\", \"dimakan\" semuanya diproses menjadi \"makan\".\n",
    "       \n",
    "3. **Tokenisasi**:\n",
    "       - Memecah teks yang sudah dibersihkan dan distemming menjadi token (kata-kata individu), yang dapat diolah lebih lanjut.\n",
    "       \n",
    "4. **Filtering Stopwords**:\n",
    "       - Menghapus stopwords (kata-kata umum yang tidak penting dalam analisis teks seperti \"yang\", \"dan\", \"di\") menggunakan daftar stopwords dari \n",
    "         bahasa Indonesia yang disediakan oleh NLTK. Ini bertujuan agar hanya kata-kata penting yang dipertahankan dalam teks.\n",
    "       \n",
    "5. **Penggabungan Kembali**:\n",
    "       - Setelah proses tokenisasi dan filtering stopwords, token yang tersisa digabung kembali menjadi satu string teks yang siap digunakan \n",
    "         dalam teknik analisis teks selanjutnya, seperti perhitungan TF-IDF atau analisis vektor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0acdc8-2ba6-41d1-8cfc-c646d6d6fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_process_text(text):\n",
    "    # Langkah pembersihan teks\n",
    "    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', text)  # Menghapus https* dan www*\n",
    "    text = re.sub(r'@[^\\s]+', ' ', text)  # Menghapus username\n",
    "    text = re.sub(r'[\\s]+', ' ', text)  # Menghapus tambahan spasi\n",
    "    text = re.sub(r'#([^\\s]+)', ' ', text)  # Menghapus hashtags\n",
    "    text = re.sub(r'rt', ' ', text)  # Menghapus retweet\n",
    "    text = re.sub(r'[^\\w\\s]+', ' ', text)  # Menghapus tanda baca\n",
    "    text = re.sub(r'\\d', ' ', text)  # Menghapus angka\n",
    "    text = text.lower()  # Mengubah teks menjadi huruf kecil\n",
    "    text = text.encode('ascii', 'ignore').decode('utf-8')  # Menghapus karakter non-ASCII\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', r'', text)  # Menghapus karakter non-ASCII yang tersisa\n",
    "    text = text.replace('\\n', '')  # Menghapus baris baru\n",
    "\n",
    "    # Langkah stemming\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "    stemmed_text = stemmer.stem(text)\n",
    "\n",
    "    # Tokenisasi\n",
    "    tokens = nltk.tokenize.word_tokenize(stemmed_text)\n",
    "    \n",
    "    # Setelah ditokenisasi, setiap token dicek apakah itu stopword atau tidak\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    filtered_words = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Gabungkan kembali kata-kata yang sudah difilter menjadi teks\n",
    "    processed_text = ' '.join(tqdm(filtered_words, desc=\"Menggabungkan kata\"))\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd8c13e9-f74b-4290-a4ff-ddee900edad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata:   0%|                                                                      | 0/349 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata: 100%|████████████████████████████████████████████████████████████████████| 349/349 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata:   0%|                                                                      | 0/187 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata: 100%|████████████████████████████████████████████████████████| 187/187 [00:00<00:00, 188496.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata:   0%|                                                                      | 0/248 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata: 100%|████████████████████████████████████████████████████████| 248/248 [00:00<00:00, 248077.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata:   0%|                                                                      | 0/355 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata: 100%|████████████████████████████████████████████████████████████████████| 355/355 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata:   0%|                                                                       | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Menggabungkan kata: 100%|██████████████████████████████████████████████████████████████████████| 84/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleansing\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43misi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_and_process_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m, in \u001b[0;36mclean_and_process_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Langkah stemming\u001b[39;00m\n\u001b[0;32m     16\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m StemmerFactory()\u001b[38;5;241m.\u001b[39mcreate_stemmer()\n\u001b[1;32m---> 17\u001b[0m stemmed_text \u001b[38;5;241m=\u001b[39m \u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Tokenisasi\u001b[39;00m\n\u001b[0;32m     20\u001b[0m tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtokenize\u001b[38;5;241m.\u001b[39mword_tokenize(stemmed_text)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\CachedStemmer.py:20\u001b[0m, in \u001b[0;36mCachedStemmer.stem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     18\u001b[0m     stems\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mget(word))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelegatedStemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mset(word, stem)\n\u001b[0;32m     22\u001b[0m     stems\u001b[38;5;241m.\u001b[39mappend(stem)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:27\u001b[0m, in \u001b[0;36mStemmer.stem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     24\u001b[0m stems \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m---> 27\u001b[0m     stems\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stems)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:36\u001b[0m, in \u001b[0;36mStemmer.stem_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstem_plural_word(word)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem_singular_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:84\u001b[0m, in \u001b[0;36mStemmer.stem_singular_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Stem a singular word to its common stem form.\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m context \u001b[38;5;241m=\u001b[39m Context(word, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisitor_provider)\n\u001b[1;32m---> 84\u001b[0m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:37\u001b[0m, in \u001b[0;36mContext.execute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute stemming process; the result can be retrieved with result\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#step 1 - 5\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_stemming_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#step 6\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:51\u001b[0m, in \u001b[0;36mContext.start_stemming_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccept_visitors(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisitors)\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdictionary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_word\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     54\u001b[0m csPrecedenceAdjustmentSpecification \u001b[38;5;241m=\u001b[39m PrecedenceAdjustmentSpecification()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Dictionary\\ArrayDictionary.py:9\u001b[0m, in \u001b[0;36mArrayDictionary.contains\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m words:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_words(words)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains\u001b[39m(\u001b[38;5;28mself\u001b[39m, word):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwords\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df[\"cleansing\"] = df[\"isi\"].apply(clean_and_process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a501054b-2fff-4a4e-ad62-49f57823d9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>isi</th>\n",
       "      <th>kategori</th>\n",
       "      <th>cleansing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Kedatangan pemain-pem...</td>\n",
       "      <td>Research</td>\n",
       "      <td>jaka a cnbc indonesia main main laga liga erop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Sepanjang paruh perta...</td>\n",
       "      <td>Research</td>\n",
       "      <td>jaka a cnbc indonesia paruh pe ama bank pelat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>Jakarta,CNBC Indonesia -Harga emas dunia melem...</td>\n",
       "      <td>Research</td>\n",
       "      <td>jaka a cnbc indonesia harga emas dunia lemah b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Indeks Harga Konsumen...</td>\n",
       "      <td>Research</td>\n",
       "      <td>jaka a cnbc indonesia indeks harga konsumen ih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>Jakarta, CNBC Indonesia-Tentara Nasional Indon...</td>\n",
       "      <td>Research</td>\n",
       "      <td>jaka a cnbc indonesia tentara nasional indones...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...   \n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...   \n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...   \n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...   \n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...   \n",
       "\n",
       "                                                 isi  kategori  \\\n",
       "0  Jakarta, CNBC Indonesia -Kedatangan pemain-pem...  Research   \n",
       "1  Jakarta, CNBC Indonesia -Sepanjang paruh perta...  Research   \n",
       "2  Jakarta,CNBC Indonesia -Harga emas dunia melem...  Research   \n",
       "3  Jakarta, CNBC Indonesia -Indeks Harga Konsumen...  Research   \n",
       "4  Jakarta, CNBC Indonesia-Tentara Nasional Indon...  Research   \n",
       "\n",
       "                                           cleansing  \n",
       "0  jaka a cnbc indonesia main main laga liga erop...  \n",
       "1  jaka a cnbc indonesia paruh pe ama bank pelat ...  \n",
       "2  jaka a cnbc indonesia harga emas dunia lemah b...  \n",
       "3  jaka a cnbc indonesia indeks harga konsumen ih...  \n",
       "4  jaka a cnbc indonesia tentara nasional indones...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ba9d8-e8bb-4795-9b41-00f1c63a89fc",
   "metadata": {},
   "source": [
    "### Perhitungan TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d17f46-15b5-461e-9bbd-c3c76b5a7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membuat Vector Space Model menggunakan TF-IDF\n",
    "def create_vsm(docs):\n",
    "    vectorizer = TfidfVectorizer() # Inisialisasi TF-IDF vectorizer\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs) # Transformasi dokumen menjadi vektor TF-IDF\n",
    "    feature_names = vectorizer.get_feature_names_out() # Mendapatkan fitur (kata-kata yang diambil oleh vectorizer)\n",
    "    df_vsm = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names) # Mengubah hasil TF-IDF menjadi DataFrame\n",
    "    return df_vsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc191d46-3f70-402c-85bb-d0b468e92b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"cleansing\"].tolist() # Ambil teks dari kolom df[\"cleansing\"] untuk digunakan dalam VSM\n",
    "vsm_df = create_vsm(docs) # Buat Vector Space Model dan simpan ke dalam DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "824d76fd-d5b8-49ec-8c1f-751961a35695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aadan</th>\n",
       "      <th>aakash</th>\n",
       "      <th>aali</th>\n",
       "      <th>aan</th>\n",
       "      <th>aba</th>\n",
       "      <th>abad</th>\n",
       "      <th>abadi</th>\n",
       "      <th>abai</th>\n",
       "      <th>abalos</th>\n",
       "      <th>abar</th>\n",
       "      <th>...</th>\n",
       "      <th>zonamegathrustbukanlah</th>\n",
       "      <th>zonamegathrusttersebut</th>\n",
       "      <th>zonamegathrustyang</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zte</th>\n",
       "      <th>zucchetto</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zulhas</th>\n",
       "      <th>zulkifli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 8786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aadan  aakash  aali  aan  aba  abad  abadi  abai  abalos  abar  ...  \\\n",
       "0      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "1      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "2      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "3      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "4      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "..     ...     ...   ...  ...  ...   ...    ...   ...     ...   ...  ...   \n",
       "393    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "394    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "395    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "396    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "397    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "\n",
       "     zonamegathrustbukanlah  zonamegathrusttersebut  zonamegathrustyang  zone  \\\n",
       "0                       0.0                     0.0                 0.0   0.0   \n",
       "1                       0.0                     0.0                 0.0   0.0   \n",
       "2                       0.0                     0.0                 0.0   0.0   \n",
       "3                       0.0                     0.0                 0.0   0.0   \n",
       "4                       0.0                     0.0                 0.0   0.0   \n",
       "..                      ...                     ...                 ...   ...   \n",
       "393                     0.0                     0.0                 0.0   0.0   \n",
       "394                     0.0                     0.0                 0.0   0.0   \n",
       "395                     0.0                     0.0                 0.0   0.0   \n",
       "396                     0.0                     0.0                 0.0   0.0   \n",
       "397                     0.0                     0.0                 0.0   0.0   \n",
       "\n",
       "     zoom  zte  zucchetto  zuckerberg  zulhas  zulkifli  \n",
       "0     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "1     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "2     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "3     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "4     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "..    ...  ...        ...         ...     ...       ...  \n",
       "393   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "394   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "395   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "396   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "397   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "\n",
       "[398 rows x 8786 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsm_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}