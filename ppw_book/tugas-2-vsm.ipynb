{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba212ae-961a-484f-b38e-bf97969ef5c5",
   "metadata": {},
   "source": [
    "# Modelling Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b432d2-558c-4185-9571-31fc5487f63a",
   "metadata": {},
   "source": [
    "## Apa itu Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e945d-3412-4f30-a7a8-417a8675d8e8",
   "metadata": {},
   "source": [
    "Vector Space Model (VSM) adalah model matematika yang digunakan untuk merepresentasikan dokumen teks sebagai vektor dari identifikator (seperti kata-kata atau token). Model ini adalah bagian fundamental dalam sistem informasi pencarian dan teknik pemrosesan bahasa alami untuk menilai dan mengurutkan dokumen berdasarkan relevansinya terhadap suatu query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f80304-d61f-46ea-a1ba-9f8e5b442191",
   "metadata": {},
   "source": [
    "### Konsep Dasar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4673cd2-0e3f-489e-8f5a-6b827b9feedb",
   "metadata": {},
   "source": [
    "Dalam VSM, setiap dimensi vektor mewakili sebuah term (kata) yang unik dalam dokumen. Nilai dalam vektor ini bisa merupakan frekuensi kemunculan kata, atau bobot yang lebih kompleks seperti TF-IDF, yang menggabungkan frekuensi kata dalam dokumen (TF) dan kebalikan frekuensi dokumen (IDF). Setiap dokumen direpresentasikan sebagai titik dalam ruang vektor ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4cfdc-c0b6-4466-94b2-a87c0204b50e",
   "metadata": {},
   "source": [
    "### Kegunaan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f92ec-6bb7-4089-807f-3847c79fe69d",
   "metadata": {},
   "source": [
    "Model ini sangat berguna dalam sistem pencarian dan pengambilan informasi karena memungkinkan operasi seperti pencarian kecocokan dan perankingan dilakukan secara matematis. VSM memfasilitasi pencocokan query pencarian dengan koleksi dokumen melalui perhitungan kedekatan vektor, menggunakan teknik seperti cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96786b4-697a-4a85-9284-af3ca696893e",
   "metadata": {},
   "source": [
    "### Keunggulan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb653836-7280-4c87-93b7-ca7f7a2528e6",
   "metadata": {},
   "source": [
    "- **Flexibilitas**: VSM memungkinkan penyertaan berbagai metode penghitungan bobot selain frekuensi term, seperti TF-IDF, yang meningkatkan efektivitas model dalam menghadapi isu seperti kata-kata yang sangat umum yang muncul di banyak dokumen.\n",
    "- **Efisiensi**: Meskipun representasi vektor dapat menjadi sangat besar, teknik seperti sparse matrix operations memungkinkan pemrosesan yang efisien.\n",
    "- **Kemampuan Komparatif**: Dengan merepresentasikan dokumen sebagai vektor, mudah untuk mengukur kesamaan antar dokumen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052984f-c71f-4a09-9e30-13c45032b475",
   "metadata": {},
   "source": [
    "### Keterbatasan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a759d5f-a50d-4781-bb6e-33cf3e6b0813",
   "metadata": {},
   "source": [
    "- **Semantik**: VSM tidak memperhitungkan konteks dan makna semantik dari kata-kata, yang bisa mengakibatkan dokumen yang sebenarnya berkaitan tidak dikenali sebagai relevan.\n",
    "- **Sinonim dan Polisemi**: Kata-kata dengan makna ganda atau sinonim mungkin tidak diproses dengan efektif, karena model ini berfokus pada kata-kata sebagai entitas independen tanpa mempertimbangkan hubungan semantiknya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea633e-438b-4411-9fd3-8df2c0a8021c",
   "metadata": {},
   "source": [
    "## Konsep TF-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad26a08e-6ff0-469c-bbec-759abd0ccd37",
   "metadata": {},
   "source": [
    "Metode  Term  Frequency-Inverse Document Frequency (TF-IDF) adalah salah satu  teknik  representasi  teks yang mengonversi kata-kata menjadi  nilai  numerik  berdasarkan  seberapa  sering kata tersebut  muncul  dalam  teks  serta  seberapa  umumnya kata tersebut  dalam  kumpulan  dokumen yang tersedia. Bobot  numerik yang dihasilkan oleh metode  ini  sering  disebut  sebagai  bobot TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71beef28-5cfe-4b01-9966-4c94165d3c9b",
   "metadata": {},
   "source": [
    "### Term Frequency (TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7b398-77ba-4207-9a21-18f601756fe1",
   "metadata": {},
   "source": [
    "**Term Frequency**: Dalam  dokumen d, frekuensi  merepresentasikan  jumlah  kemunculan kata t. Oleh karena  itu, kita  dapat  melihat  bahwa  frekuensi  menjadi  lebih  relevan  ketika  sebuah kata muncul di dalam  teks, yang mana hal  ini  rasional. Karena urutan  istilah  tidak  signifikan, kita  dapat  menggunakan  vektor  untuk  menggambarkan  teks  dalam  kantong model istilah. Untuk  setiap  istilah  tertentu  dalam  teks, ada  sebuah  entri  dengan  nilai yang merupakan  frekuensi  istilah. Bobot  sebuah  istilah yang muncul  dalam  sebuah  dokumen  secara  sederhana  sebanding  dengan  frekuensi  istilah  tersebut\n",
    "\n",
    "\n",
    "$$\n",
    "    tf(t, d) = \\frac{\\text{jumalah } t \\text{ dalam } d}{\\text{jumlah kata dalam } d}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**Dokument Frequency**: mengukur  seberapa  umumnya  suatu kata terjadi di seluruh  koleksi  dokumen. Konsep  ini  mirip  dengan Term Frequency (TF), namun  perbedaannya  terletak pada bagaimana  kita  menghitung  kemunculan  suatu kata. Di TF, kita  melihat  seberapa  sering kata muncul  dalam  satu  dokumen  tertentu, sedangkan di DF, kita  melihat  berapa  banyak  dokumen yang mengandung kata tersebut di dalam  keseluruhan  koleksi  dokumen. Jadi, Document Frequency (DF) adalah  jumlah  dokumen yang memuat  suatu kata.\n",
    "\n",
    "$$\n",
    "    df(t) = \\text{kemunculan } t \\text{ dalam } dokumen \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b485854-a92c-471d-80d2-1f2da7440d19",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a871eb4d-7059-4922-b2ca-863cd7acdcad",
   "metadata": {},
   "source": [
    "**Inverse Document Frequency (IDF)**: mengevaluasi tingkat relevansi suatu kata dalam konteks pencarian. Ketika mencari informasi, tujuan utama adalah menemukan dokumen yang paling sesuai dengan permintaan pengguna. Mengingat bahwa Term Frequency (TF) memperlakukan semua kata dengan nilai yang sama, frekuensi kata itu sendiri tidak cukup untuk menilai  bobot istilah dalam sebuah dokumen. IDF pertama-tama mencari frekuensi kemunculan dokumen untuk suatu kata dengan menghitung jumlah dokumen yang mengandung kata tersebut.\n",
    "\n",
    "$$\n",
    "    df(t) = N(t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    df(t) = \\text{Frekuensi dokumen dari suatu istilah t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    N(t) = \\text{Jumlah } dokumen \\text{ yang mengandung istilah } t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e1c7c-ac5e-402e-8f6e-727c0f0d950f",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dea39c-7929-49c9-84f2-149f1080638b",
   "metadata": {},
   "source": [
    "Term Frequency adalah jumlah kemunculan suatu term dalam satu dokumen saja, sedangkan Document Frequency adalah jumlah dokumen terpisah tempat istilah tersebut muncul. Namun, frekuensi ini bergantung pada seluruh korpus. IDF merupakan jumlah dokumen dalam korpus yang dipisahkan oleh frekuensi teks. Dengan kata lain, IDF mengukur seberapa umum atau langka suatu kata dalam seluruh koleksi dokumen.\n",
    "\n",
    "$$\n",
    "    idf(t) = \\frac{N}{df(t)}=\\frac{N}{N(t)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    idf(t) = log_2 \\frac{N}{df(t)}\n",
    "$$\n",
    "\n",
    "Maka dari itu rumus dari TF * IDF adalah sebagai berikut:\n",
    "\n",
    "$$\n",
    "    tf-idf(t, d) = tf(t, d) * idf(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f19a1-d93e-4ccb-82e4-9c553895c73a",
   "metadata": {},
   "source": [
    "## Modelling SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea207d6-dd39-4b9f-bfd6-aa759ddf3a0d",
   "metadata": {},
   "source": [
    "### Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11ea8d69-4555-412b-9954-08012a648457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library yang dibutuhkan \n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a45f2-23c5-4ea0-8300-3ea2acf75c65",
   "metadata": {},
   "source": [
    "Data yang sebelumnya sudah discrapping pada [tugas 1](https://rrayhka.github.io/pencarian-penambangan-web/tugas-1-crawling.html#convert-data-ke-dalam-csv) diimport untuk dijadikan VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4007f0d-6bba-4436-8d9a-cb822d8ee012",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data-artikel-cnbc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82c44ab6-6096-47f4-870a-515166173954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>isi</th>\n",
       "      <th>url</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>09 September 2024 19:30</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Kedatangan pemain-pem...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>09 September 2024 19:05</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Sepanjang paruh perta...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>09 September 2024 18:10</td>\n",
       "      <td>Jakarta,CNBC Indonesia -Harga emas dunia melem...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>09 September 2024 15:55</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Indeks Harga Konsumen...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>09 September 2024 14:35</td>\n",
       "      <td>Jakarta, CNBC Indonesia-Tentara Nasional Indon...</td>\n",
       "      <td>https://www.cnbcindonesia.com/research/2024090...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul                  tanggal  \\\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...  09 September 2024 19:30   \n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...  09 September 2024 19:05   \n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...  09 September 2024 18:10   \n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...  09 September 2024 15:55   \n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...  09 September 2024 14:35   \n",
       "\n",
       "                                                 isi  \\\n",
       "0  Jakarta, CNBC Indonesia -Kedatangan pemain-pem...   \n",
       "1  Jakarta, CNBC Indonesia -Sepanjang paruh perta...   \n",
       "2  Jakarta,CNBC Indonesia -Harga emas dunia melem...   \n",
       "3  Jakarta, CNBC Indonesia -Indeks Harga Konsumen...   \n",
       "4  Jakarta, CNBC Indonesia-Tentara Nasional Indon...   \n",
       "\n",
       "                                                 url  kategori  \n",
       "0  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "1  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "2  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "3  https://www.cnbcindonesia.com/research/2024090...  Research  \n",
       "4  https://www.cnbcindonesia.com/research/2024090...  Research  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bcd779f-a60a-4957-b864-32be6ce2d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>isi</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Kedatangan pemain-pem...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Sepanjang paruh perta...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>Jakarta,CNBC Indonesia -Harga emas dunia melem...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Indeks Harga Konsumen...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>Jakarta, CNBC Indonesia-Tentara Nasional Indon...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...   \n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...   \n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...   \n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...   \n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...   \n",
       "\n",
       "                                                 isi  kategori  \n",
       "0  Jakarta, CNBC Indonesia -Kedatangan pemain-pem...  Research  \n",
       "1  Jakarta, CNBC Indonesia -Sepanjang paruh perta...  Research  \n",
       "2  Jakarta,CNBC Indonesia -Harga emas dunia melem...  Research  \n",
       "3  Jakarta, CNBC Indonesia -Indeks Harga Konsumen...  Research  \n",
       "4  Jakarta, CNBC Indonesia-Tentara Nasional Indon...  Research  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hanya memilih kolom judul, isi, dan kategori\n",
    "df = df[['judul', 'isi','kategori']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "638fa620-4b0f-4b4f-9b82-7837c8e5a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data untuk kategori \"Research\" dan \"News\" masing-masing diambil 50 berita\n",
    "research = df[df[\"kategori\"] == \"Research\"].sample(n=50, random_state=42)\n",
    "news = df[df[\"kategori\"] == \"News\"].sample(n=50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb4e7672-ce4c-481c-97ee-2fd121c2bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan keduanya\n",
    "data = pd.concat([research, news], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6030e6d5-325d-4da3-9321-014164040ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   judul     100 non-null    object\n",
      " 1   isi       100 non-null    object\n",
      " 2   kategori  100 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "651978f8-4ac1-4eb1-a7d8-ec0181f9b227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>isi</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Kedatangan pemain-pem...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Sepanjang paruh perta...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emas Meredup Saat Suku Bunga The Fed Mau Turun...</td>\n",
       "      <td>Jakarta,CNBC Indonesia -Harga emas dunia melem...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...</td>\n",
       "      <td>Jakarta, CNBC Indonesia -Indeks Harga Konsumen...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tantama Hingga Perwira, Ini Urutan Lengkap Pan...</td>\n",
       "      <td>Jakarta, CNBC Indonesia-Tentara Nasional Indon...</td>\n",
       "      <td>Research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Bukan Kaleng-kaleng! Nilai Skuad Timnas Indone...   \n",
       "1  Aset Bank Mandiri Tembus Rp 2.200 T, Paling Ju...   \n",
       "2  Emas Meredup Saat Suku Bunga The Fed Mau Turun...   \n",
       "3  Tetangga RI Dihantam 'Bencana' Iklim, Harga Ba...   \n",
       "4  Tantama Hingga Perwira, Ini Urutan Lengkap Pan...   \n",
       "\n",
       "                                                 isi  kategori  \n",
       "0  Jakarta, CNBC Indonesia -Kedatangan pemain-pem...  Research  \n",
       "1  Jakarta, CNBC Indonesia -Sepanjang paruh perta...  Research  \n",
       "2  Jakarta,CNBC Indonesia -Harga emas dunia melem...  Research  \n",
       "3  Jakarta, CNBC Indonesia -Indeks Harga Konsumen...  Research  \n",
       "4  Jakarta, CNBC Indonesia-Tentara Nasional Indon...  Research  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb011254-f714-4783-9d4c-dba5ccc42948",
   "metadata": {},
   "source": [
    "#### Cleansing Function\n",
    "\n",
    "1. **Pembersihan Teks**:\n",
    "       - Menghapus URL yang diawali dengan \"www.\" atau \"https://\", agar tidak mengganggu hasil analisis.\n",
    "       - Menghapus mention username yang diawali dengan '@' untuk menghindari gangguan dari referensi ke akun sosial media.\n",
    "       - Menghapus spasi berlebih yang muncul akibat pembersihan teks sebelumnya.\n",
    "       - Menghapus hashtag (kata yang diawali dengan '#'), karena hashtag tidak diperlukan dalam analisis konten.\n",
    "       - Menghapus teks 'RT' (retweet) yang biasa ditemukan dalam tweet.\n",
    "       - Menghapus tanda baca seperti titik, koma, tanda seru, dan karakter non-alfanumerik lainnya.\n",
    "       - Menghapus angka dari teks karena angka biasanya tidak berkontribusi pada pemahaman konteks dalam teks (kecuali dalam analisis numerik).\n",
    "       - Mengubah teks menjadi huruf kecil agar seragam dalam pengolahan, terutama dalam analisis berbasis kata.\n",
    "       - Menghapus karakter non-ASCII untuk menghindari simbol atau karakter yang tidak dikenal di encoding ASCII.\n",
    "       - Menghapus karakter tambahan non-ASCII yang mungkin masih tersisa di dalam teks.\n",
    "       - Menghapus baris baru ('\\n') agar hasilnya berupa satu baris teks yang konsisten.\n",
    "\n",
    "2. **Stemming**:\n",
    "       - Menggunakan library `Sastrawi` untuk stemming teks bahasa Indonesia. Stemming adalah proses mengubah kata-kata menjadi bentuk dasar (akar kata), \n",
    "         sehingga kata yang beragam seperti \"makan\", \"memakan\", \"dimakan\" semuanya diproses menjadi \"makan\".\n",
    "       \n",
    "3. **Tokenisasi**:\n",
    "       - Memecah teks yang sudah dibersihkan dan distemming menjadi token (kata-kata individu), yang dapat diolah lebih lanjut.\n",
    "       \n",
    "4. **Filtering Stopwords**:\n",
    "       - Menghapus stopwords (kata-kata umum yang tidak penting dalam analisis teks seperti \"yang\", \"dan\", \"di\") menggunakan daftar stopwords dari \n",
    "         bahasa Indonesia yang disediakan oleh NLTK. Ini bertujuan agar hanya kata-kata penting yang dipertahankan dalam teks.\n",
    "       \n",
    "5. **Penggabungan Kembali**:\n",
    "       - Setelah proses tokenisasi dan filtering stopwords, token yang tersisa digabung kembali menjadi satu string teks yang siap digunakan \n",
    "         dalam teknik analisis teks selanjutnya, seperti perhitungan TF-IDF atau analisis vektor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e3709c",
   "metadata": {},
   "source": [
    "#### Fungsi clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50a4a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\ttext = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', text) # Menghapus https* and www*\n",
    "\ttext = re.sub(r'@[^\\s]+', ' ', text) # Menghapus username\n",
    "\ttext = re.sub(r'[\\s]+', ' ', text) # Menghapus tambahan spasi\n",
    "\ttext = re.sub(r'#([^\\s]+)', ' ', text) # Menghapus hashtags\n",
    "\ttext = re.sub(r'rt', ' ', text) # Menghapus retweet\n",
    "\ttext = text.translate(str.maketrans(\"\",\"\",string.punctuation)) # Menghapus tanda baca\n",
    "\ttext = re.sub(r'\\d', ' ', text) # Menghapus angka\n",
    "\ttext = text.lower()\n",
    "\ttext = text.encode('ascii','ignore').decode('utf-8') #Menghapus ASCII dan unicode\n",
    "\ttext = re.sub(r'[^\\x00-\\x7f]',r'', text)\n",
    "\ttext = text.replace('\\n','') #Menghapus baris baru\n",
    "\ttext = text.strip()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e0b455",
   "metadata": {},
   "source": [
    "#### Fungsi Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35316e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_indo(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d401974",
   "metadata": {},
   "source": [
    "#### Fungsi clean Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaf64ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stopword(tokens):\n",
    "\tlistStopword =  set(stopwords.words('indonesian'))\n",
    "\tremoved = []\n",
    "\tfor t in tokens:\n",
    "\t\tif t not in listStopword:\n",
    "\t\t\tremoved.append(t)\n",
    "\treturn removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a5adf",
   "metadata": {},
   "source": [
    "### Splitting dataset 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "traini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde75f4",
   "metadata": {},
   "source": [
    "### Proses penerapan preposesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dae51e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/398 [00:32<19:19,  3.00s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m tqdm(content):\n\u001b[0;32m      4\u001b[0m \tcleaned_doc \u001b[38;5;241m=\u001b[39m clean_text(doc)\n\u001b[1;32m----> 5\u001b[0m \tstemmed_doc \u001b[38;5;241m=\u001b[39m \u001b[43mstemming_indo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_doc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \ttokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtokenize\u001b[38;5;241m.\u001b[39mword_tokenize(stemmed_doc)\n\u001b[0;32m      7\u001b[0m \tcleaned_tokens \u001b[38;5;241m=\u001b[39m clean_stopword(tokens)\n",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m, in \u001b[0;36mstemming_indo\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m factory \u001b[38;5;241m=\u001b[39m StemmerFactory()\n\u001b[0;32m      3\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m factory\u001b[38;5;241m.\u001b[39mcreate_stemmer()\n\u001b[1;32m----> 4\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\CachedStemmer.py:20\u001b[0m, in \u001b[0;36mCachedStemmer.stem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     18\u001b[0m     stems\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mget(word))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelegatedStemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mset(word, stem)\n\u001b[0;32m     22\u001b[0m     stems\u001b[38;5;241m.\u001b[39mappend(stem)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:27\u001b[0m, in \u001b[0;36mStemmer.stem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     24\u001b[0m stems \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m---> 27\u001b[0m     stems\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stems)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:36\u001b[0m, in \u001b[0;36mStemmer.stem_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstem_plural_word(word)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem_singular_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py:84\u001b[0m, in \u001b[0;36mStemmer.stem_singular_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Stem a singular word to its common stem form.\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m context \u001b[38;5;241m=\u001b[39m Context(word, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisitor_provider)\n\u001b[1;32m---> 84\u001b[0m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:37\u001b[0m, in \u001b[0;36mContext.execute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute stemming process; the result can be retrieved with result\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#step 1 - 5\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_stemming_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#step 6\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:75\u001b[0m, in \u001b[0;36mContext.start_stemming_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremovals \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m#step 2, 3\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove_suffixes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:94\u001b[0m, in \u001b[0;36mContext.remove_suffixes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_suffixes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_visitors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffix_visitors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:101\u001b[0m, in \u001b[0;36mContext.accept_visitors\u001b[1;34m(self, visitors)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccept_visitors\u001b[39m(\u001b[38;5;28mself\u001b[39m, visitors):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m visitor \u001b[38;5;129;01min\u001b[39;00m visitors:\n\u001b[1;32m--> 101\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisitor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word):\n\u001b[0;32m    103\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_word\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py:96\u001b[0m, in \u001b[0;36mContext.accept\u001b[1;34m(self, visitor)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_suffixes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccept_visitors(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffix_visitors)\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccept\u001b[39m(\u001b[38;5;28mself\u001b[39m, visitor):\n\u001b[0;32m     97\u001b[0m     visitor\u001b[38;5;241m.\u001b[39mvisit(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccept_visitors\u001b[39m(\u001b[38;5;28mself\u001b[39m, visitors):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "content = df['isi']\n",
    "all_docs = []\n",
    "for doc in tqdm(content):\n",
    "\tcleaned_doc = clean_text(doc)\n",
    "\tstemmed_doc = stemming_indo(cleaned_doc)\n",
    "\ttokens = nltk.tokenize.word_tokenize(stemmed_doc)\n",
    "\tcleaned_tokens = clean_stopword(tokens)\n",
    "\tjoined_strings = []\n",
    "\tall_docs.append(' '.join(cleaned_tokens))\n",
    "print(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb0db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ba9d8-e8bb-4795-9b41-00f1c63a89fc",
   "metadata": {},
   "source": [
    "### Perhitungan TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d17f46-15b5-461e-9bbd-c3c76b5a7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membuat Vector Space Model menggunakan TF-IDF\n",
    "def create_vsm(docs):\n",
    "    vectorizer = TfidfVectorizer() # Inisialisasi TF-IDF vectorizer\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs) # Transformasi dokumen menjadi vektor TF-IDF\n",
    "    feature_names = vectorizer.get_feature_names_out() # Mendapatkan fitur (kata-kata yang diambil oleh vectorizer)\n",
    "    df_vsm = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names) # Mengubah hasil TF-IDF menjadi DataFrame\n",
    "    return df_vsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc191d46-3f70-402c-85bb-d0b468e92b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"cleansing\"].tolist() # Ambil teks dari kolom df[\"cleansing\"] untuk digunakan dalam VSM\n",
    "vsm_df = create_vsm(docs) # Buat Vector Space Model dan simpan ke dalam DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824d76fd-d5b8-49ec-8c1f-751961a35695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aadan</th>\n",
       "      <th>aakash</th>\n",
       "      <th>aali</th>\n",
       "      <th>aan</th>\n",
       "      <th>aba</th>\n",
       "      <th>abad</th>\n",
       "      <th>abadi</th>\n",
       "      <th>abai</th>\n",
       "      <th>abalos</th>\n",
       "      <th>abar</th>\n",
       "      <th>...</th>\n",
       "      <th>zonamegathrustbukanlah</th>\n",
       "      <th>zonamegathrusttersebut</th>\n",
       "      <th>zonamegathrustyang</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zte</th>\n",
       "      <th>zucchetto</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zulhas</th>\n",
       "      <th>zulkifli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 8786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aadan  aakash  aali  aan  aba  abad  abadi  abai  abalos  abar  ...  \\\n",
       "0      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "1      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "2      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "3      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "4      0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "..     ...     ...   ...  ...  ...   ...    ...   ...     ...   ...  ...   \n",
       "393    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "394    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "395    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "396    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "397    0.0     0.0   0.0  0.0  0.0   0.0    0.0   0.0     0.0   0.0  ...   \n",
       "\n",
       "     zonamegathrustbukanlah  zonamegathrusttersebut  zonamegathrustyang  zone  \\\n",
       "0                       0.0                     0.0                 0.0   0.0   \n",
       "1                       0.0                     0.0                 0.0   0.0   \n",
       "2                       0.0                     0.0                 0.0   0.0   \n",
       "3                       0.0                     0.0                 0.0   0.0   \n",
       "4                       0.0                     0.0                 0.0   0.0   \n",
       "..                      ...                     ...                 ...   ...   \n",
       "393                     0.0                     0.0                 0.0   0.0   \n",
       "394                     0.0                     0.0                 0.0   0.0   \n",
       "395                     0.0                     0.0                 0.0   0.0   \n",
       "396                     0.0                     0.0                 0.0   0.0   \n",
       "397                     0.0                     0.0                 0.0   0.0   \n",
       "\n",
       "     zoom  zte  zucchetto  zuckerberg  zulhas  zulkifli  \n",
       "0     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "1     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "2     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "3     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "4     0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "..    ...  ...        ...         ...     ...       ...  \n",
       "393   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "394   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "395   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "396   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "397   0.0  0.0        0.0         0.0     0.0       0.0  \n",
       "\n",
       "[398 rows x 8786 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsm_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
